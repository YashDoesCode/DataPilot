"""
Tools module for the Kaggle Experiment Assistant Agent (KEAA).

This module implements the functions that the agent can call to interact with
the Kaggle environment, including data loading, code execution, and logging.
"""

import os
import json
import pandas as pd
import numpy as np
import datetime
from typing import Dict, List, Any, Optional, Union
import traceback
import io
import sys

# Import configuration to get paths
try:
    from config import default_config
except ImportError:
    # Fallback for when running tools.py directly or in isolation
    from dataclasses import dataclass
    @dataclass
    class MockConfig:
        kaggle = type('obj', (object,), {'experiments_dir': '/kaggle/working/experiments'})
    default_config = type('obj', (object,), {'kaggle': MockConfig()})

def list_files(directory: str) -> List[str]:
    """
    Lists all files in a directory recursively.

    Args:
        directory: The path to the directory to search.

    Returns:
        A list of file paths found in the directory.
    """
    file_list = []
    if not os.path.exists(directory):
        return [f"Error: Directory '{directory}' does not exist."]
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_list.append(os.path.join(root, file))
    return file_list

def load_data(filepath: str, nrows: Optional[int] = None) -> str:
    """
    Loads a CSV or Parquet file into a pandas DataFrame and returns a summary.
    
    Note: This tool does NOT return the DataFrame object itself to the agent (which is text-based).
    It returns a string description of the loaded data. The actual DataFrame is stored
    in a global context if needed, or this tool is just for inspection.
    
    For the agent to *use* the data, it should generate code using `execute_code`
    that loads the data itself. This tool is primarily for the agent to *peek* at the data.

    Args:
        filepath: Path to the file.
        nrows: Number of rows to load (optional, for large files).

    Returns:
        A string summary of the dataframe (columns, dtypes, head).
    """
    try:
        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath, nrows=nrows)
        elif filepath.endswith('.parquet'):
            df = pd.read_parquet(filepath)
            if nrows:
                df = df.head(nrows)
        else:
            return f"Error: Unsupported file format for '{filepath}'. Use CSV or Parquet."

        buffer = io.StringIO()
        df.info(buf=buffer)
        info_str = buffer.getvalue()
        
        return f"Successfully loaded '{filepath}'.\nShape: {df.shape}\n\nInfo:\n{info_str}\n\nFirst 5 rows:\n{df.head().to_string()}"
    except Exception as e:
        return f"Error loading data: {str(e)}"

def summarize_data(filepath: str) -> str:
    """
    Generates descriptive statistics for a dataset.
    
    Args:
        filepath: Path to the file to summarize.
        
    Returns:
        JSON string with descriptive statistics.
    """
    try:
        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
        elif filepath.endswith('.parquet'):
            df = pd.read_parquet(filepath)
        else:
            return "Error: Unsupported file format."
            
        desc = df.describe(include='all').to_string()
        missing = df.isnull().sum().to_string()
        
        return f"Descriptive Statistics:\n{desc}\n\nMissing Values:\n{missing}"
    except Exception as e:
        return f"Error summarizing data: {str(e)}"

def execute_code(code: str) -> str:
    """
    Executes a string of Python code in a controlled environment.
    
    The code has access to pandas (pd), numpy (np), sklearn, and standard library modules.
    It captures stdout and stderr.
    
    Args:
        code: The Python code to execute.
        
    Returns:
        A string containing the standard output and any errors.
    """
    # Create a buffer to capture stdout
    old_stdout = sys.stdout
    redirected_output = sys.stdout = io.StringIO()
    
    # Define the execution context
    local_scope = {}
    global_scope = {
        "pd": pd,
        "np": np,
        "os": os,
        "json": json,
    }
    
    try:
        # We wrap the code execution in a try-except block within the exec
        # to ensure we catch runtime errors generated by the code itself.
        exec(code, global_scope, local_scope)
        output = redirected_output.getvalue()
        return f"Execution Success:\n{output}"
    except Exception:
        # Capture the traceback if the code fails
        error_msg = traceback.format_exc()
        return f"Execution Error:\n{error_msg}"
    finally:
        # Restore stdout
        sys.stdout = old_stdout

def log_experiment(experiment_data: Dict[str, Any]) -> str:
    """
    Logs an experiment to a JSON file.
    
    Args:
        experiment_data: A dictionary containing experiment details.
                         Should include: experiment_id, description, model, metrics, etc.
                         
    Returns:
        Confirmation message.
    """
    try:
        # Ensure timestamp is present
        if "timestamp" not in experiment_data:
            experiment_data["timestamp"] = datetime.datetime.now().isoformat()
            
        # Define log file path
        log_dir = default_config.kaggle.experiments_dir
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, "experiment_log.json")
        
        # Load existing logs or create new list
        if os.path.exists(log_file):
            with open(log_file, 'r') as f:
                try:
                    logs = json.load(f)
                    if not isinstance(logs, list):
                        logs = []
                except json.JSONDecodeError:
                    logs = []
        else:
            logs = []
            
        logs.append(experiment_data)
        
        with open(log_file, 'w') as f:
            json.dump(logs, f, indent=2)
            
        return f"Experiment logged successfully to {log_file}."
    except Exception as e:
        return f"Error logging experiment: {str(e)}"

def save_text(filename: str, content: str) -> str:
    """
    Saves text content to a file in the working directory.
    
    Args:
        filename: Name of the file (relative to /kaggle/working).
        content: Text content to save.
        
    Returns:
        Confirmation message.
    """
    try:
        filepath = os.path.join(default_config.kaggle.working_dir, filename)
        with open(filepath, 'w') as f:
            f.write(content)
        return f"File saved to {filepath}."
    except Exception as e:
        return f"Error saving file: {str(e)}"

# Dictionary mapping tool names to functions for easy lookup by the agent
AVAILABLE_TOOLS = {
    "list_files": list_files,
    "load_data": load_data,
    "summarize_data": summarize_data,
    "execute_code": execute_code,
    "log_experiment": log_experiment,
    "save_text": save_text
}
